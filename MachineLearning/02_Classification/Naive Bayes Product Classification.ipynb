{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load JSON Data\n",
    "json_data = None\n",
    "json_data = 'trainingdata_catnumbers.json'\n",
    "data = pd.read_json(json_data, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape with duplicates:  (1318, 31)\n",
      "Shape without duplicates:  (1310, 31)\n"
     ]
    }
   ],
   "source": [
    "#check for duplicates:\n",
    "print('Shape with duplicates: ', data.shape)\n",
    "data.drop_duplicates(subset=['uniq_id'], inplace=True)\n",
    "print('Shape without duplicates: ', data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store id of labeled data:\n",
    "labeled_ids = data.uniq_id.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Convert Category Column to int\n",
    "data['category'] = data['category'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    DIGITAL Funda Airpods Silicone 1 Case+Carabine...\n",
       "1    GadgetBite Anti-Lost Magnetic Strap Silicone C...\n",
       "2    Wow Imagine MonoCarbon Genuine Carbon Fiber Ul...\n",
       "3    Brain Freezer Skin Soft Silicone Dual Layer Ul...\n",
       "4    Case-Mate AirPods Pro Tough Case Cover Silicon...\n",
       "Name: product_name, dtype: object"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.product_name.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/hannah/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#add stemmer: maps different forms of the same word to a common “stem” \n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "#add stopwords: to remove irrelevant words from text\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "#add english stopwords\n",
    "words = stopwords.words(\"english\")\n",
    "\n",
    "#Preprocessing: apply stemmer and remove stopwords\n",
    "data['cleaned'] = data['product_name'].apply(lambda x: \" \".join([stemmer.stem(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).split() if i not in words]).lower())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assing data and labels:\n",
    "X = data['cleaned'] #data\n",
    "y = data.category #labels\n",
    "\n",
    "#split data into train and test data (80/20-Split) including the cleaned product names column (x) and the category column (y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stratified cross-validation 5-fold (results in 20% Test- and 80% Trainingdata)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1310"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add a pipeline to build the model: contains a list of transforms \n",
    "\n",
    "#CountVectorizer: Converts a collection of text to a matrix of token counts \n",
    "#TfidfTransformer: gives every word a weight depending of their frequency\n",
    "#SelectPercentile: Selects defined percentile of best fitting features by using chi2-Test\n",
    "#MultinomialNB: Applies Multinomial Naive Bayes\n",
    "\n",
    "\n",
    "pipeline = Pipeline([('vect', CountVectorizer(ngram_range=(1, 2), stop_words=\"english\")),\n",
    "                     ('tfid', TfidfTransformer(sublinear_tf=False)),\n",
    "                     ('chi',  SelectPercentile(chi2, percentile=50)),\n",
    "                     ('clf', MultinomialNB())\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stop time for training:\n",
    "start_training_time = time.time()\n",
    "\n",
    "#fit model with 80/20 split:\n",
    "model = pipeline.fit(X_train, y_train)\n",
    "\n",
    "#stop time:\n",
    "total_training_time = (time.time() - start_training_time)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score 80/20 split: 0.7900763358778626\n",
      "accuracy cross-val per fold:  [0.81679389 0.80534351 0.8129771  0.83587786 0.80534351]\n",
      "accuracy cross-val mean:  0.815267175572519\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy score 80/20 split: \" + str(model.score(X_test, y_test)))\n",
    "\n",
    "#get crossvalidation scores:\n",
    "scoring = ['accuracy']\n",
    "cv_results = cross_validate(pipeline, X, y, scoring=scoring, cv=skf)\n",
    "\n",
    "\n",
    "#print crossvalidation scores:\n",
    "print(\"accuracy cross-val per fold: \", cv_results['test_accuracy'])\n",
    "print(\"accuracy cross-val mean: \", np.mean(cv_results['test_accuracy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime for training in seconds:  0.12810230255126953\n",
      "runtime for training in seconds mean:  0.0972982406616211\n"
     ]
    }
   ],
   "source": [
    "#runtime for 80/20 split training: \n",
    "print(\"runtime for training in seconds: \", total_training_time)\n",
    "\n",
    "#get runtime of cross-validation:\n",
    "print(\"runtime for training in seconds mean: \", np.mean(cv_results['fit_time']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview categories and their corresponding numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Electronic Accessories\" -> 1\n",
    "# Electronic Accessories | Smartphone Accessories -> 11\n",
    "# Electronic Accessories | Smartphone Accessories | Mobile Covers -> 111\n",
    "# Electronic Accessories | Smartphone Accessories | Mobile Covers | Flip Covers -> 1111\n",
    "# Electronic Accessories | Smartphone Accessories | Mobile Covers | Covers with Stand -> 1112\n",
    "# Electronic Accessories | Headphones -> 12\n",
    "# Electronic Accessories | Headphones | Headphone Accessories -> 121\n",
    "# Electronic Accessories | Tablet Accessories -> 13\n",
    "# Electronic Accessories | Chargers and Adapters -> 14\n",
    "# Electronic Accessories | Batteries -> 15\n",
    "# Electronic Accessories | Batteries | Camera Batteries -> 151\n",
    "# Electronic Accessories | Cables -> 16\n",
    "# Electronic Accessories | Cables | HDMI Cables -> 161\n",
    "# Electronic Accessories | Screen Protectors -> 17\n",
    "# Electronic Accessories | Camera Accessories -> 18\n",
    "# Electronic Accessories | Camera Accessories | Camera Filters and Lenses -> 181\n",
    "# Electronic Accessories | Laptop Accessories -> 19\n",
    "# Electronic Accessories | Laptop Accessories | Laptop Bags and Backpacks -> 191\n",
    "# Electronic Accessories | Laptop Accessories | Laptop Sleeves -> 192\n",
    "# Electronic Accessories | Memory Cards -> 2\n",
    "# Electronic Accessories | Keyboards -> 3\n",
    "# Electronic Accessories | Keyboards | Keyboard Accessories -> 31\n",
    "# Electronic Accessories | Mice -> 4\n",
    "# Electronic Accessories | Mice | Mouse Pads -> 41\n",
    "# Electronic Accessories | TV Accessories -> 5\n",
    "# Electronic Accessories | Power Supplies -> 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prediction results for 80/20 simple split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[41]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(['Peace Hand - Gel Wrist Rest Support Mouse Pad - Non-slip - Anti-skid - for Computer - PC - Laptop Black']))\n",
    "#should be 41 (Electronic Accessories | Mice | Mouse Pads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1112]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(['Aarfa Slimfit Durable Printed Hard Case for Xiaomi Redmi 4 (4X)']))\n",
    "#should be 111 (Electronic Accessories | Smartphone Accessories | Mobile Covers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[161]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(['C&E CNE622576 (60 Feet/18.2 Meters) High Speed HDMI Cable Male to Male with Ethernet and Audio Return (Black)']))\n",
    "#should be 161 (Electronic Accessories | Cables | HDMI Cables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(['Saco Transparent Laptop Touchpad Protector for All Laptops (Clear, 158x98 mm)']))\n",
    "#should be 19 (Electronic Accessories | Laptop Accessories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[192]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(['Verbatim Bravo Wired Notebook Optical Mouse, Black (98106)']))\n",
    "#should be 4 (Electronic Accessories | Mice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1111]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(['FOSO F36 PU Leather Magnetic Flip Cover Wallet Back Cover for Honor View 20 (Brown)']))\n",
    "#should be 1111 (Electronic Accessories | Smartphone Accessories | Mobile Covers | Flip Covers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit model on all labeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime for training in seconds:  0.11916422843933105\n"
     ]
    }
   ],
   "source": [
    "#stop time for training:\n",
    "start_training_time = time.time()\n",
    "\n",
    "#fit model with data and labels:\n",
    "model = pipeline.fit(X, y)\n",
    "\n",
    "#stop time:\n",
    "total_training_time = (time.time() - start_training_time)\n",
    "\n",
    "#runtime for training: \n",
    "print(\"runtime for training in seconds: \", total_training_time)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load unlabeled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load json dataset \n",
    "json_file = 'Amazon_Electronics_2_cleaned.json'\n",
    "\n",
    "#convert json string to pandas object and save it to data\n",
    "data = pd.read_json(json_file, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of unlabeled data:  8690\n"
     ]
    }
   ],
   "source": [
    "#filter for unlabeled data: \n",
    "data_unlabeled = data[~data['uniq_id'].isin(labeled_ids)].copy(deep=True)\n",
    "print('size of unlabeled data: ', data_unlabeled.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cazcase Deer Pattern Smart Case Cover Flip Sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D-kandy for Gionee A1 Lite, Fashion Series Lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>iPhone 6 Case, LUVVITT® ULTRA ARMOR iPhone 6 C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Redgear MPR800 Soft Base Mousepad with 4 LED S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Aimo Wireless IPH5PCLP002 Rubber Essentials Sl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        product_name\n",
       "0  Cazcase Deer Pattern Smart Case Cover Flip Sta...\n",
       "1  D-kandy for Gionee A1 Lite, Fashion Series Lea...\n",
       "3  iPhone 6 Case, LUVVITT® ULTRA ARMOR iPhone 6 C...\n",
       "4  Redgear MPR800 Soft Base Mousepad with 4 LED S...\n",
       "6  Aimo Wireless IPH5PCLP002 Rubber Essentials Sl..."
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#select relevant column and copy it into product_names\n",
    "product_names = data_unlabeled[['product_name']].copy()\n",
    "\n",
    "#show data\n",
    "product_names.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    cazcas deer pattern smart case cover flip stan...\n",
       "1    d kandi gione a lite fashion seri leather flip...\n",
       "3    iphon case luvvitt ultra armor iphon case best...\n",
       "4     redgear mpr soft base mousepad led spectrum mode\n",
       "6    aimo wireless iph pclp rubber essenti slim dur...\n",
       "Name: cleaned, dtype: object"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#preprocessing: apply stemming & lower case on each row of product_names. Save cleaned data in new column \"cleaned\"\n",
    "product_names['cleaned'] = product_names['product_name'].apply(lambda x: \" \".join([stemmer.stem(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).split() if i not in words]).lower())\n",
    "\n",
    "#show cleaned data\n",
    "product_names['cleaned'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime for prediction in seconds for 0.2754089832305908 titles: 8690\n"
     ]
    }
   ],
   "source": [
    "#stop time for prediction:\n",
    "start_training_time = time.time()\n",
    "\n",
    "#predict labels\n",
    "predicted_labels = model.predict(product_names['cleaned'])\n",
    "\n",
    "#stop time:\n",
    "total_training_time = (time.time() - start_training_time)\n",
    "\n",
    "#runtime for training: \n",
    "print(\"runtime for prediction in seconds for {} titles: {}\".format(total_training_time,len(predicted_labels)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
